{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling the full df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_full = pd.read_pickle(\"../data/full_df_posts.pkl\")\n",
    "df_full[\"n_tokens\"] = df_full[\"caption\"].apply(lambda x: len(x.split(\" \")))\n",
    "df_full = df_full.query(\"n_tokens > 10\")\n",
    "\n",
    "df_sample = pd.concat(\n",
    "    [\n",
    "        df_full.query(\"country == 'US' & has_disclosures\").sample(1000),\n",
    "        df_full.query(\"country == 'US' & ~has_disclosures\").sample(1000),\n",
    "    ]\n",
    ").to_pickle(\"../data/df_sample.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generation Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from instasynth.config import Config, logger\n",
    "from instasynth import data_generation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "Config.PROMPTS_FOLDER = Path(\"../instasynth/prompts\")\n",
    "Config.RESULTS_FOLDER = Path(\"../instasynth/results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'instasynth.data_generation' from '../instasynth/data_generation.py'>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(data_generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "DATA_PATH = \"../data\"\n",
    "SAMPLE_DATASET_SIZE = 1000\n",
    "ORIGINAL_PICKLE_FILENAME = \"df_sample.pkl\"\n",
    "\n",
    "\n",
    "def get_sampled_dataset(\n",
    "    original_pickle_filename: str,\n",
    "    sample_size: int,\n",
    "    fixed_sample: bool = False,\n",
    "    random_state: int = 18,\n",
    "    keep_columns: List[str] = [\"caption\", \"has_disclosures\"],\n",
    "):\n",
    "    dataset_filename = f\"{DATA_PATH}/sample_{sample_size}_{random_state}.csv\"\n",
    "\n",
    "    # Check if the sample dataset already exists\n",
    "    if fixed_sample and os.path.exists(dataset_filename):\n",
    "        logger.info(\"Loading sample dataset...\")\n",
    "        sample_dataset = pd.read_csv(dataset_filename)\n",
    "    else:\n",
    "        logger.info(\"Creating sample dataset...\")\n",
    "        full_df_filename = f\"{DATA_PATH}/{original_pickle_filename}\"\n",
    "        full_df = pd.read_pickle(full_df_filename)\n",
    "\n",
    "        # Split the dataset into sponsored and unsponsored based on the 'has_disclosures' column\n",
    "        sponsored = full_df.query(\"has_disclosures\").sample(\n",
    "            sample_size, random_state=random_state\n",
    "        )\n",
    "        unsponsored = full_df.query(\"~has_disclosures\").sample(\n",
    "            sample_size, random_state=random_state\n",
    "        )\n",
    "\n",
    "        sample_dataset = pd.concat([sponsored, unsponsored])[keep_columns]\n",
    "        sample_dataset.to_csv(dataset_filename, index=False)\n",
    "\n",
    "    return sample_dataset\n",
    "\n",
    "\n",
    "def format_examples(examples: list) -> str:\n",
    "    \"\"\"Format examples for display.\"\"\"\n",
    "    return \"\".join(\n",
    "        [\n",
    "            f\"{index + 1}. <POST> {example} </POST>\\n\"\n",
    "            for index, example in enumerate(examples)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "def get_caption_examples(number_examples, sponsored=False):\n",
    "    \"\"\"Retrieve a set of caption examples from the dataset.\"\"\"\n",
    "    sample_dataset = get_sampled_dataset(\n",
    "        original_pickle_filename=ORIGINAL_PICKLE_FILENAME,\n",
    "        sample_size=int(SAMPLE_DATASET_SIZE / 2),\n",
    "    )\n",
    "    examples = (\n",
    "        sample_dataset.query(f\"has_disclosures == {sponsored}\")[\"caption\"]\n",
    "        .sample(number_examples)\n",
    "        .tolist()\n",
    "    )\n",
    "    examples = [example.replace(\"\\n\", \"\") for example in examples]\n",
    "\n",
    "    return format_examples(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-08-18 11:25:53,969 - INFO - Creating sample dataset...\n",
      "2023-08-18 11:25:54,010 - INFO - Running experiment nonsponsored_random_examples_exp_1 with prompt nonsponsored_random_examples and parameters {'number_of_examples': 5, 'number_of_captions': 25, 'examples': '1. <POST> <in love with my new @shouroukr bracelet I picked up @thestyleliner this weekend> </POST>\\n2. <POST> Is #princess and downgrade from #queen ü§™ kidding üòúHave a seat...let‚Äôs talk! #princessoftheredcarpet–¥–∞–≤–∞–π –ø–æ–≥–æ–≤–æ—Ä–∏–º!My new cover feature in @thesurrealmag Photographer @gilzetbase Art Director and Producer @angeladonava MUA @jm_honeyz Hair @tatianadorogaia </POST>\\n3. <POST> Me encanto este lugar, esta espectacular!!! Vayan a mi snapchat sincerelymvu a chequearloüòò </POST>\\n4. <POST> Nothing better than a late night game of #SettlersOfCatan üèÜ#HomeForTheHolidays #NerdAlert </POST>\\n5. <POST> Morning stretch and flex! üí™üèª‚úåüèªÔ∏èüëô‚ú®‚≠êÔ∏è‚ù§Ô∏èüíãüåä‚òÄÔ∏è‚≠êÔ∏è @si_swimsuit @tracymurphymua @mj_day @riadazar9 @jamesmacari @ja_neyney </POST>\\n'}\n",
      "2023-08-18 11:25:54,013 - INFO - Sending messages to OpenAI API...\n",
      "2023-08-18 11:26:02,398 - INFO - Received response from OpenAI API!\n",
      "2023-08-18 11:26:02,399 - INFO - Processing response...\n",
      "2023-08-18 11:26:02,401 - INFO - Storing results...\n",
      "2023-08-18 11:26:02,406 - INFO - Experiment complete!\n"
     ]
    }
   ],
   "source": [
    "experiment_identifier = \"nonsponsored_random_examples_exp_1\"\n",
    "prompt_name = \"nonsponsored_random_examples\"\n",
    "\n",
    "number_of_examples = 5\n",
    "number_of_captions = 25\n",
    "examples = get_caption_examples(number_examples=number_of_examples, sponsored=False)\n",
    "\n",
    "parameters={\"number_of_examples\": number_of_examples,\n",
    "            \"number_of_captions\": number_of_captions,\n",
    "            \"examples\": examples}\n",
    "\n",
    "_ = data_generation.create_experiment(experiment_identifier, prompt_name, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
