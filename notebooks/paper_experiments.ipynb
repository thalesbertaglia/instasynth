{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Results and Tables\n",
    "\n",
    "This notebook contains the code to reproduce the main results and tables in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `agg_df` is the dataframe containing the results of the experiments. It is created by running the `evaluation.ipynb` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 500)\n",
    "pd.set_option(\"display.max_columns\", 500)\n",
    "pd.set_option(\"display.width\", 1000)\n",
    "\n",
    "agg_df = pd.read_pickle(\"aggregated_df.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4 -- Selecting the model temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = agg_df.index.tolist()\n",
    "selected_columns = [\n",
    "    \"pct_unique_captions\",\n",
    "    \"success_rate\",\n",
    "    \"ad_detection_f1\",\n",
    "    \"ad_detection_undisclosed_accuracy\",\n",
    "    \"top_100_recall_cosine_sim\",\n",
    "    \"avg_hashtags_per_post\",\n",
    "    \"avg_user_tags_per_post\",\n",
    "    \"hashtag_overlap\",\n",
    "    \"user_tag_overlap\",\n",
    "    # \"jaccard_similarity_3gram\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 1 -- Impact of temperature parameter on dataset characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from instasynth import utils\n",
    "\n",
    "base_prompts = [k for k in experiments if \"base_prompt_v2_temperature_\" in k]\n",
    "\n",
    "column_map = {\n",
    "    \"pct_unique_captions\": \"Unique Captions (\\%)\",\n",
    "    \"success_rate\": \"Success Rate (\\%)\",\n",
    "    # \"ad_detection_f1\": \"Ad Detection F1\",\n",
    "    # \"ad_detection_undisclosed_accuracy\": \"Undisc. Ad Detection Acc\",\n",
    "    # \"top_100_recall_cosine_sim\": \"Top-100 Sim. Recall\",\n",
    "    # \"avg_hashtags_per_post\": \"Avg. Hashtags\",\n",
    "    # \"avg_user_tags_per_post\": \"Avg. User Tags\",\n",
    "    \"hashtag_overlap\": \"Hashtag Overlap (\\%)\",\n",
    "    \"user_tag_overlap\": \"User Tag Overlap (\\%)\",\n",
    "}\n",
    "index_map = {k: f\"{k.split('_')[-1]}\" for k in base_prompts}\n",
    "temperature_table = agg_df.loc[base_prompts][selected_columns].sort_index()\n",
    "\n",
    "for k in [\"pct_unique_captions\", \"success_rate\", \"hashtag_overlap\", \"user_tag_overlap\"]:\n",
    "    temperature_table[k] = temperature_table[k] * 100\n",
    "\n",
    "utils.generate_latex_table(\n",
    "    temperature_table.T,\n",
    "    table_caption=\"Impact of temperature parameter on dataset characteristics.\",\n",
    "    table_label=\"tab:temperatures\",\n",
    "    columns_rename_map=index_map,\n",
    "    index_rename_map=column_map,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\\begin{table}\n",
    "\\centering\n",
    "\\caption{Impact of temperature parameter on dataset characteristics.}\n",
    "\\label{tab:temperatures}\n",
    "\\begin{tabular}{lccccc}\n",
    "\\toprule\n",
    " & \\bfseries 0 & \\bfseries 0.25 & \\bfseries 0.5 & \\bfseries 0.7 & \\bfseries 1 \\\\\n",
    "\\midrule\n",
    "\\bfseries Unique Captions (\\%) & 42.32 & 92.48 & 97.51 & 99.41 & 100.00 \\\\\n",
    "\\bfseries Success Rate (\\%) & 100.00 & 95.24 & 87.74 & 83.81 & 74.83 \\\\\n",
    "\\bfseries ad_detection_f1 & 0.65 & 0.64 & 0.64 & 0.64 & 0.64 \\\\\n",
    "\\bfseries ad_detection_undisclosed_accuracy & 0.78 & 0.80 & 0.78 & 0.74 & 0.76 \\\\\n",
    "\\bfseries top_100_recall_cosine_sim & 0.10 & 0.10 & 0.10 & 0.11 & 0.10 \\\\\n",
    "\\bfseries avg_hashtags_per_post & 0.73 & 1.02 & 0.97 & 0.96 & 0.88 \\\\\n",
    "\\bfseries avg_user_tags_per_post & 0.32 & 0.28 & 0.29 & 0.33 & 0.25 \\\\\n",
    "\\bfseries Hashtag Overlap (\\%) & 0.46 & 0.98 & 0.98 & 0.95 & 0.81 \\\\\n",
    "\\bfseries User Tag Overlap (\\%) & 0.00 & 0.00 & 0.00 & 0.07 & 0.07 \\\\\n",
    "\\bottomrule\n",
    "\\end{tabular}\n",
    "\\end{table}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_base = \"base_prompt_v2_temperature_0.7\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting the datasets for the remaining prompt strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fixed examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pct_unique_captions</th>\n",
       "      <th>success_rate</th>\n",
       "      <th>ad_detection_f1</th>\n",
       "      <th>ad_detection_undisclosed_accuracy</th>\n",
       "      <th>top_100_recall_cosine_sim</th>\n",
       "      <th>avg_hashtags_per_post</th>\n",
       "      <th>avg_user_tags_per_post</th>\n",
       "      <th>hashtag_overlap</th>\n",
       "      <th>user_tag_overlap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fixed_examples_ht_v1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.810526</td>\n",
       "      <td>0.621580</td>\n",
       "      <td>0.409204</td>\n",
       "      <td>0.091266</td>\n",
       "      <td>0.962709</td>\n",
       "      <td>0.160942</td>\n",
       "      <td>0.010367</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fixed_examples_ht_v2</th>\n",
       "      <td>0.854455</td>\n",
       "      <td>0.877551</td>\n",
       "      <td>0.542289</td>\n",
       "      <td>0.225124</td>\n",
       "      <td>0.105941</td>\n",
       "      <td>1.043564</td>\n",
       "      <td>0.667327</td>\n",
       "      <td>0.010771</td>\n",
       "      <td>0.011782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fixed_examples_post_v1</th>\n",
       "      <td>0.999017</td>\n",
       "      <td>0.867470</td>\n",
       "      <td>0.606127</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.098328</td>\n",
       "      <td>1.146509</td>\n",
       "      <td>0.186824</td>\n",
       "      <td>0.013147</td>\n",
       "      <td>0.001423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fixed_examples_post_v2</th>\n",
       "      <td>0.966102</td>\n",
       "      <td>0.949580</td>\n",
       "      <td>0.660793</td>\n",
       "      <td>0.399254</td>\n",
       "      <td>0.124626</td>\n",
       "      <td>1.077767</td>\n",
       "      <td>0.527418</td>\n",
       "      <td>0.011609</td>\n",
       "      <td>0.011236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        pct_unique_captions  success_rate  ad_detection_f1  \\\n",
       "fixed_examples_ht_v1               1.000000      0.810526         0.621580   \n",
       "fixed_examples_ht_v2               0.854455      0.877551         0.542289   \n",
       "fixed_examples_post_v1             0.999017      0.867470         0.606127   \n",
       "fixed_examples_post_v2             0.966102      0.949580         0.660793   \n",
       "\n",
       "                        ad_detection_undisclosed_accuracy  \\\n",
       "fixed_examples_ht_v1                             0.409204   \n",
       "fixed_examples_ht_v2                             0.225124   \n",
       "fixed_examples_post_v1                           0.333333   \n",
       "fixed_examples_post_v2                           0.399254   \n",
       "\n",
       "                        top_100_recall_cosine_sim  avg_hashtags_per_post  \\\n",
       "fixed_examples_ht_v1                     0.091266               0.962709   \n",
       "fixed_examples_ht_v2                     0.105941               1.043564   \n",
       "fixed_examples_post_v1                   0.098328               1.146509   \n",
       "fixed_examples_post_v2                   0.124626               1.077767   \n",
       "\n",
       "                        avg_user_tags_per_post  hashtag_overlap  \\\n",
       "fixed_examples_ht_v1                  0.160942         0.010367   \n",
       "fixed_examples_ht_v2                  0.667327         0.010771   \n",
       "fixed_examples_post_v1                0.186824         0.013147   \n",
       "fixed_examples_post_v2                0.527418         0.011609   \n",
       "\n",
       "                        user_tag_overlap  \n",
       "fixed_examples_ht_v1            0.000000  \n",
       "fixed_examples_ht_v2            0.011782  \n",
       "fixed_examples_post_v1          0.001423  \n",
       "fixed_examples_post_v2          0.011236  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fixed_examples = [k for k in experiments if \"fixed_examples\" in k]\n",
    "agg_df.loc[fixed_examples][selected_columns].sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_fixed_examples = \"fixed_examples_post_v2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_examples = [\n",
    "    k for k in experiments if \"random_examples\" in k and \"imitation\" not in k\n",
    "]\n",
    "selected_random_examples = \"random_examples_post_v2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imitation examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "imitation_examples = [k for k in experiments if \"imitation\" in k]\n",
    "selected_imitation = \"imitation_random_examples_ht_v2_temperature_0.7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_experiments = [selected_base, selected_fixed_examples, selected_random_examples, selected_imitation, \"Real\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pct_unique_captions</th>\n",
       "      <th>success_rate</th>\n",
       "      <th>ad_detection_f1</th>\n",
       "      <th>ad_detection_undisclosed_accuracy</th>\n",
       "      <th>top_100_recall_cosine_sim</th>\n",
       "      <th>avg_hashtags_per_post</th>\n",
       "      <th>avg_user_tags_per_post</th>\n",
       "      <th>hashtag_overlap</th>\n",
       "      <th>user_tag_overlap</th>\n",
       "      <th>jaccard_similarity_3gram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>base_prompt_v2_temperature_0.7</th>\n",
       "      <td>0.994094</td>\n",
       "      <td>0.838095</td>\n",
       "      <td>0.636948</td>\n",
       "      <td>0.740050</td>\n",
       "      <td>0.111220</td>\n",
       "      <td>0.955709</td>\n",
       "      <td>0.333661</td>\n",
       "      <td>0.009516</td>\n",
       "      <td>0.000655</td>\n",
       "      <td>0.009895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fixed_examples_post_v2</th>\n",
       "      <td>0.966102</td>\n",
       "      <td>0.949580</td>\n",
       "      <td>0.660793</td>\n",
       "      <td>0.399254</td>\n",
       "      <td>0.124626</td>\n",
       "      <td>1.077767</td>\n",
       "      <td>0.527418</td>\n",
       "      <td>0.011609</td>\n",
       "      <td>0.011236</td>\n",
       "      <td>0.017144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_examples_post_v2</th>\n",
       "      <td>0.999004</td>\n",
       "      <td>0.917910</td>\n",
       "      <td>0.709398</td>\n",
       "      <td>0.512438</td>\n",
       "      <td>0.102590</td>\n",
       "      <td>1.053785</td>\n",
       "      <td>0.563745</td>\n",
       "      <td>0.028432</td>\n",
       "      <td>0.045154</td>\n",
       "      <td>0.022285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imitation_random_examples_ht_v2_temperature_0.7</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.915493</td>\n",
       "      <td>0.707019</td>\n",
       "      <td>0.232587</td>\n",
       "      <td>0.101779</td>\n",
       "      <td>1.169960</td>\n",
       "      <td>0.704545</td>\n",
       "      <td>0.034249</td>\n",
       "      <td>0.040456</td>\n",
       "      <td>0.024766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Real</th>\n",
       "      <td>0.999005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.787307</td>\n",
       "      <td>0.442786</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.775124</td>\n",
       "      <td>1.730348</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 pct_unique_captions  \\\n",
       "base_prompt_v2_temperature_0.7                              0.994094   \n",
       "fixed_examples_post_v2                                      0.966102   \n",
       "random_examples_post_v2                                     0.999004   \n",
       "imitation_random_examples_ht_v2_temperature_0.7             1.000000   \n",
       "Real                                                        0.999005   \n",
       "\n",
       "                                                 success_rate  \\\n",
       "base_prompt_v2_temperature_0.7                       0.838095   \n",
       "fixed_examples_post_v2                               0.949580   \n",
       "random_examples_post_v2                              0.917910   \n",
       "imitation_random_examples_ht_v2_temperature_0.7      0.915493   \n",
       "Real                                                      NaN   \n",
       "\n",
       "                                                 ad_detection_f1  \\\n",
       "base_prompt_v2_temperature_0.7                          0.636948   \n",
       "fixed_examples_post_v2                                  0.660793   \n",
       "random_examples_post_v2                                 0.709398   \n",
       "imitation_random_examples_ht_v2_temperature_0.7         0.707019   \n",
       "Real                                                    0.787307   \n",
       "\n",
       "                                                 ad_detection_undisclosed_accuracy  \\\n",
       "base_prompt_v2_temperature_0.7                                            0.740050   \n",
       "fixed_examples_post_v2                                                    0.399254   \n",
       "random_examples_post_v2                                                   0.512438   \n",
       "imitation_random_examples_ht_v2_temperature_0.7                           0.232587   \n",
       "Real                                                                      0.442786   \n",
       "\n",
       "                                                 top_100_recall_cosine_sim  \\\n",
       "base_prompt_v2_temperature_0.7                                    0.111220   \n",
       "fixed_examples_post_v2                                            0.124626   \n",
       "random_examples_post_v2                                           0.102590   \n",
       "imitation_random_examples_ht_v2_temperature_0.7                   0.101779   \n",
       "Real                                                                   NaN   \n",
       "\n",
       "                                                 avg_hashtags_per_post  \\\n",
       "base_prompt_v2_temperature_0.7                                0.955709   \n",
       "fixed_examples_post_v2                                        1.077767   \n",
       "random_examples_post_v2                                       1.053785   \n",
       "imitation_random_examples_ht_v2_temperature_0.7               1.169960   \n",
       "Real                                                          2.775124   \n",
       "\n",
       "                                                 avg_user_tags_per_post  \\\n",
       "base_prompt_v2_temperature_0.7                                 0.333661   \n",
       "fixed_examples_post_v2                                         0.527418   \n",
       "random_examples_post_v2                                        0.563745   \n",
       "imitation_random_examples_ht_v2_temperature_0.7                0.704545   \n",
       "Real                                                           1.730348   \n",
       "\n",
       "                                                 hashtag_overlap  \\\n",
       "base_prompt_v2_temperature_0.7                          0.009516   \n",
       "fixed_examples_post_v2                                  0.011609   \n",
       "random_examples_post_v2                                 0.028432   \n",
       "imitation_random_examples_ht_v2_temperature_0.7         0.034249   \n",
       "Real                                                         NaN   \n",
       "\n",
       "                                                 user_tag_overlap  \\\n",
       "base_prompt_v2_temperature_0.7                           0.000655   \n",
       "fixed_examples_post_v2                                   0.011236   \n",
       "random_examples_post_v2                                  0.045154   \n",
       "imitation_random_examples_ht_v2_temperature_0.7          0.040456   \n",
       "Real                                                          NaN   \n",
       "\n",
       "                                                 jaccard_similarity_3gram  \n",
       "base_prompt_v2_temperature_0.7                                   0.009895  \n",
       "fixed_examples_post_v2                                           0.017144  \n",
       "random_examples_post_v2                                          0.022285  \n",
       "imitation_random_examples_ht_v2_temperature_0.7                  0.024766  \n",
       "Real                                                                  NaN  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_df.loc[selected_experiments][selected_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['base_prompt_v2_temperature_0.7',\n",
       " 'fixed_examples_post_v2',\n",
       " 'random_examples_post_v2',\n",
       " 'imitation_random_examples_ht_v2_temperature_0.7',\n",
       " 'Real']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4 -- Caption Composition Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 2 -- Impact of prompt-engineering strategies on dataset characteristics; values within brackets represent the number of unique entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "caption_composition_columns = [\n",
    "    \"avg_caption_length\",\n",
    "    \"std_caption_length\",\n",
    "    \"avg_hashtags_per_post\",\n",
    "    \"std_hashtags_per_post\",\n",
    "    # \"total_hashtags\",\n",
    "    \"n_unique_hashtags\",\n",
    "    \"avg_user_tags_per_post\",\n",
    "    \"std_user_tags_per_post\",\n",
    "    # \"total_user_tags\",\n",
    "    \"n_unique_user_tags\",\n",
    "    \"avg_emojis_per_post\",\n",
    "    \"std_emojis_per_post\",\n",
    "    # \"total_emojis\",\n",
    "    \"n_unique_emojis\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_df = agg_df.copy()\n",
    "for k in [\"hashtags\", \"user_tags\", \"emojis\"]:\n",
    "    avg = f\"avg_{k}_per_post\"\n",
    "    std = f\"std_{k}_per_post\"\n",
    "    unique = f\"n_unique_{k}\"\n",
    "    table_df[f\"{k}\"] = table_df.apply(\n",
    "        lambda x: f\"{x[avg]:.2f}$\\pm${x[std]:.2f} ({x[unique]:.0f})\", axis=1\n",
    "    )\n",
    "table_df[\"caption_length\"] = table_df.apply(\n",
    "    lambda x: f\"{x['avg_caption_length']:.2f}$\\pm${x['std_caption_length']:.2f}\", axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_composition = table_df.loc[selected_experiments][\n",
    "    [\"caption_length\", \"hashtags\", \"user_tags\", \"emojis\"]\n",
    "]\n",
    "column_map = {\n",
    "    \"caption_length\": \"Caption Length\",\n",
    "    \"hashtags\": \"Hashtags\",\n",
    "    \"n_unique_hashtags\": \"Unique\",\n",
    "    \"user_tags\": \"User Tags\",\n",
    "    \"n_unique_user_tags\": \"Unique\",\n",
    "    \"emojis\": \"Emojis\",\n",
    "    \"n_unique_emojis\": \"Unique\",\n",
    "}\n",
    "index_map = {\n",
    "    \"base_prompt_v2_temperature_0.7\": \"Base Prompt\",\n",
    "    \"fixed_examples_post_v2\": \"Fixed Examples\",\n",
    "    \"random_examples_post_v2\": \"Random Examples\",\n",
    "    \"imitation_random_examples_ht_v2_temperature_0.7\": \"Imitation\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.generate_latex_table(\n",
    "    table_composition,\n",
    "    table_caption=\"Impact of prompt-engineering strategies on dataset characteristics; values within brackets represent the number of unique entities.\",\n",
    "    table_label=\"tab:composition_metrics\",\n",
    "    columns_rename_map=column_map,\n",
    "    index_rename_map=index_map,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\\begin{table}\n",
    "\\centering\n",
    "\\caption{Impact of prompt-engineering strategies on dataset characteristics; values within brackets represent the number of unique entities.}\n",
    "\\label{tab:composition_metrics}\n",
    "\\begin{tabular}{lcccc}\n",
    "\\toprule\n",
    " & \\bfseries Caption Length & \\bfseries Hashtags & \\bfseries User Tags & \\bfseries Emojis \\\\\n",
    "\\midrule\n",
    "\\bfseries Base Prompt & 21.92$\\pm$10.92 & 0.96$\\pm$0.78 (484) & 0.33$\\pm$0.48 (293) & 2.04$\\pm$1.34 (257) \\\\\n",
    "\\bfseries Fixed Examples & 33.49$\\pm$24.52 & 1.08$\\pm$0.82 (591) & 0.53$\\pm$1.14 (206) & 2.33$\\pm$2.15 (232) \\\\\n",
    "\\bfseries Random Examples & 28.38$\\pm$16.42 & 1.05$\\pm$0.83 (685) & 0.56$\\pm$0.73 (502) & 2.12$\\pm$1.36 (325) \\\\\n",
    "\\bfseries Imitation & 35.65$\\pm$15.65 & 1.17$\\pm$0.90 (899) & 0.70$\\pm$0.77 (595) & 2.15$\\pm$1.44 (355) \\\\\n",
    "\\bfseries Real & 42.86$\\pm$52.12 & 1.97$\\pm$3.20 (1348) & 1.38$\\pm$1.87 (996) & 1.88$\\pm$2.72 (448) \\\\\n",
    "\\bottomrule\n",
    "\\end{tabular}\n",
    "\\end{table}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4 -- Content Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 3 -- Content overlap metrics between synthetic and real datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_analysis_columns = (\n",
    "    [\"hashtag_overlap\", \"user_tag_overlap\"]\n",
    "    + [c for c in agg_df.columns if \"jaccard\" in c]\n",
    "    # + [c for c in agg_df.columns if \"pronouns\" in c]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_map = {\n",
    "    **{\n",
    "        \"hashtag_overlap\": \"Hashtag Overlap (\\%)\",\n",
    "        \"user_tag_overlap\": \"User Tag Overlap (\\%)\",\n",
    "    },\n",
    "    **{\n",
    "        k: f\"{k.split('_')[-1][0]}-gram Sim. (\\%)\"\n",
    "        for k in content_analysis_columns\n",
    "        if \"jaccard\" in k\n",
    "    },\n",
    "}\n",
    "\n",
    "_selected_experiments = [k for k in selected_experiments if k != \"Real\"]\n",
    "\n",
    "content_metrics_table = agg_df.loc[_selected_experiments][content_analysis_columns]\n",
    "for k in content_analysis_columns:\n",
    "    content_metrics_table[k] = content_metrics_table[k] * 100\n",
    "\n",
    "utils.generate_latex_table(\n",
    "    content_metrics_table.T,\n",
    "    table_caption=\"Content overlap metrics between synthetic and real datasets.\",\n",
    "    table_label=\"tab:content_metrics\",\n",
    "    columns_rename_map=index_map,\n",
    "    index_rename_map=column_map,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\\begin{table}\n",
    "\\centering\n",
    "\\caption{Content overlap metrics between synthetic and real datasets.}\n",
    "\\label{tab:content_metrics}\n",
    "\\begin{tabular}{lcccc}\n",
    "\\toprule\n",
    " & \\bfseries Base Prompt & \\bfseries Fixed Examples & \\bfseries Random Examples & \\bfseries Imitation \\\\\n",
    "\\midrule\n",
    "\\bfseries Hashtag Overlap (\\%) & 0.95 & 1.16 & 2.84 & 3.42 \\\\\n",
    "\\bfseries User Tag Overlap (\\%) & 0.07 & 1.12 & 4.52 & 4.05 \\\\\n",
    "\\bfseries 1-gram Sim. (\\%) & 12.72 & 15.16 & 19.75 & 21.24 \\\\\n",
    "\\bfseries 2-gram Sim. (\\%) & 4.70 & 6.01 & 7.36 & 8.36 \\\\\n",
    "\\bfseries 3-gram Sim. (\\%) & 0.99 & 1.71 & 2.23 & 2.48 \\\\\n",
    "\\bottomrule\n",
    "\\end{tabular}\n",
    "\\end{table}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 4 -- Distribution of emoji skin tones across each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji\n",
    "\n",
    "skins_tones = [\n",
    "    f\"{k}_skin_tone\" for k in [\"light\", \"medium-light\", \"medium\", \"medium-dark\", \"dark\"]\n",
    "]\n",
    "\n",
    "\n",
    "def get_skin_tone_counter(df: pd.DataFrame):\n",
    "    df[\"emojis\"] = df.caption.apply(\n",
    "        lambda x: [emoji.demojize(k[\"emoji\"]) for k in emoji.emoji_list(x)]\n",
    "    )\n",
    "    emoji_counter = Counter()\n",
    "    df[\"emojis\"].apply(emoji_counter.update)\n",
    "    return {\n",
    "        tone: sum((v for k, v in emoji_counter.items() if tone in k))\n",
    "        for tone in skins_tones\n",
    "    }\n",
    "\n",
    "def sample_real(full_df: pd.DataFrame, seed: int):\n",
    "    spons = full_df.query(\"sponsorship == 'sponsored'\").sample(500, random_state=seed)\n",
    "    nonspons = full_df.query(\"sponsorship == 'nonsponsored'\").sample(\n",
    "        500, random_state=seed\n",
    "    )\n",
    "    return pd.concat([spons, nonspons]).sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "bootstrap_skin_tone_counter = defaultdict(int)\n",
    "\n",
    "for i in range(100):\n",
    "    for k, v in get_skin_tone_counter(sample_real(full_data, i)).items():\n",
    "        bootstrap_skin_tone_counter[k] += v\n",
    "\n",
    "bootstrap_skin_tone_counter = {k: v / 100 for k, v in bootstrap_skin_tone_counter.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "skin_tone_counter = {\n",
    "    f: get_skin_tone_counter(pd.read_pickle(f\"../results/{f}/final_df.pkl\"))\n",
    "    for f in selected_experiments\n",
    "    if f != \"Real\"\n",
    "}\n",
    "skin_tone_counter[\"Real\"] = bootstrap_skin_tone_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_map = {\n",
    "    \"light_skin_tone\": \"Light\",\n",
    "    \"medium-light_skin_tone\": \"Medium-Light\",\n",
    "    \"medium_skin_tone\": \"Medium\",\n",
    "    \"medium-dark_skin_tone\": \"Medium-Dark\",\n",
    "    \"dark_skin_tone\": \"Dark\",\n",
    "}\n",
    "\n",
    "skin_tone_table = pd.DataFrame(skin_tone_counter)\n",
    "\n",
    "utils.generate_latex_table(\n",
    "    skin_tone_table.T,\n",
    "    table_caption=\"Distribution of emoji skin tones across each dataset\",\n",
    "    table_label=\"tab:skin_tone\",\n",
    "    columns_rename_map=column_map,\n",
    "    index_rename_map=index_map,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\\begin{table}\n",
    "\\centering\n",
    "\\caption{Distribution of emoji skin tones across each dataset}\n",
    "\\label{tab:skin_tone}\n",
    "\\begin{tabular}{lccccc}\n",
    "\\toprule\n",
    " & \\bfseries Light & \\bfseries Medium-Light & \\bfseries Medium & \\bfseries Medium-Dark & \\bfseries Dark \\\\\n",
    "\\midrule\n",
    "\\bfseries Base Prompt & 36.00 & 26.00 & 0.00 & 0.00 & 0.00 \\\\\n",
    "\\bfseries Fixed Examples & 27.00 & 17.00 & 50.00 & 0.00 & 0.00 \\\\\n",
    "\\bfseries Random Examples & 62.00 & 35.00 & 8.00 & 1.00 & 1.00 \\\\\n",
    "\\bfseries Imitation & 52.00 & 36.00 & 2.00 & 3.00 & 3.00 \\\\\n",
    "\\bfseries Real & 235.08 & 155.82 & 26.60 & 22.43 & 25.63 \\\\\n",
    "\\bottomrule\n",
    "\\end{tabular}\n",
    "\\end{table}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4 -- Embedding Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 5 -- Embedding similarity metrics between captions from each synthetic dataset and the real data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_similarity_columns = [\n",
    "    c\n",
    "    for c in agg_df.columns\n",
    "    if \"cosine\" in c\n",
    "    and (\"avg\" in c or \"std\" in c or \"100_recall\" in c)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_map = {\n",
    "    \"avg_cosine_sim\": \"Similarity\",\n",
    "    \"top_100_recall_cosine_sim\": \"Top-100 Recall\",\n",
    "    # \"synthetic_internal_cosine_sim\": \"Internal Similarity\",\n",
    "}\n",
    "\n",
    "embedding_similarity_table = agg_df.loc[_selected_experiments][\n",
    "    embedding_similarity_columns\n",
    "].copy()\n",
    "embedding_similarity_table[\"avg_cosine_sim\"] = embedding_similarity_table.apply(\n",
    "    lambda x: f\"{x['avg_cosine_sim']:.2f}$\\pm${x['std_cosine_sim']:.2f}\", axis=1\n",
    ")\n",
    "embedding_similarity_table.drop(columns=[\"std_cosine_sim\"], inplace=True)\n",
    "\n",
    "utils.generate_latex_table(\n",
    "    embedding_similarity_table,\n",
    "    table_caption=\"Embedding similarity metrics between captions from each synthetic dataset and the real data.\",\n",
    "    table_label=\"tab:embedding_similarity\",\n",
    "    columns_rename_map=columns_map,\n",
    "    index_rename_map=index_map,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\\begin{table}\n",
    "\\centering\n",
    "\\caption{Embedding similarity metrics between captions from each synthetic dataset and the real data.}\n",
    "\\label{tab:embedding_similarity}\n",
    "\\begin{tabular}{lcc}\n",
    "\\toprule\n",
    " & \\bfseries Similarity & \\bfseries Top-100 Recall \\\\\n",
    "\\midrule\n",
    "\\bfseries Base Prompt & 0.83$\\pm$0.02 & 0.11 \\\\\n",
    "\\bfseries Fixed Examples & 0.84$\\pm$0.05 & 0.12 \\\\\n",
    "\\bfseries Random Examples & 0.83$\\pm$0.03 & 0.10 \\\\\n",
    "\\bfseries Imitation & 0.83$\\pm$0.03 & 0.10 \\\\\n",
    "\\bottomrule\n",
    "\\end{tabular}\n",
    "\\end{table}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4 -- Network-based Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 6 -- Network metrics for the three classes of networks analysed: hashtag co-occurrence (HT), usertag co-occurrence (UT), and hashtag-user bipartite network (HU). Columns correspond to the four synthetic datasets we analyse and the real dataset. The values reported are averaged over 100 network instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_columns = [\n",
    "    c\n",
    "    for c in agg_df.columns\n",
    "    if \"NW\" in c\n",
    "    and (\n",
    "        \"nodes\" in c\n",
    "        or \"edges\" in c\n",
    "        or \"clustering\" in c\n",
    "        or \"degree\" in c\n",
    "        or \"assortativity\" in c\n",
    "    )\n",
    "]\n",
    "\n",
    "nw_table = agg_df.loc[selected_experiments][network_columns]\n",
    "column_map = {\n",
    "    k: k.replace(\"NW_\", \"\")\n",
    "    .replace(\"hashtag_usertag_\", \"HU \")\n",
    "    .replace(\"hashtag_\", \"HT \")\n",
    "    .replace(\"usertag_\", \"UT \")\n",
    "    .replace(\"number_of_\", \"\\# \")\n",
    "    .replace(\"avg_\", \"Avg. \")\n",
    "    .replace(\"nodes\", \"Nodes\")\n",
    "    .replace(\"edges\", \"Edges\")\n",
    "    .replace(\"degree\", \"Degree\")\n",
    "    .replace(\"clustering_coefficient\", \"Clustering Coeff.\")\n",
    "    .replace(\"assortativity\", \"Assortativity\")\n",
    "    .replace(\"_\", \"\\_\")\n",
    "    for k in nw_table.columns\n",
    "}\n",
    "\n",
    "utils.generate_latex_table(\n",
    "    nw_table.T,\n",
    "    table_caption=\"Network metrics for the three classes of networks analysed: hashtag co-occurrence (HT), usertag co-occurrence (UT), and hashtag-user bipartite network (HU). Columns correspond to the four synthetic datasets we analyse and the real dataset. The values reported are averaged over 100 network instances.\",\n",
    "    table_label=\"tab:network_metrics\",\n",
    "    columns_rename_map=index_map,\n",
    "    index_rename_map=column_map,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NW_hashtag_number_of_nodes</th>\n",
       "      <th>NW_hashtag_number_of_edges</th>\n",
       "      <th>NW_hashtag_avg_clustering_coefficient</th>\n",
       "      <th>NW_hashtag_avg_degree</th>\n",
       "      <th>NW_hashtag_assortativity</th>\n",
       "      <th>NW_usertag_number_of_nodes</th>\n",
       "      <th>NW_usertag_number_of_edges</th>\n",
       "      <th>NW_usertag_avg_clustering_coefficient</th>\n",
       "      <th>NW_usertag_avg_degree</th>\n",
       "      <th>NW_usertag_assortativity</th>\n",
       "      <th>NW_hashtag_usertag_number_of_nodes</th>\n",
       "      <th>NW_hashtag_usertag_number_of_edges</th>\n",
       "      <th>NW_hashtag_usertag_avg_clustering_coefficient</th>\n",
       "      <th>NW_hashtag_usertag_avg_degree</th>\n",
       "      <th>NW_hashtag_usertag_assortativity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>base_prompt_v2_temperature_0.7</th>\n",
       "      <td>484.00</td>\n",
       "      <td>237.00</td>\n",
       "      <td>0.017235</td>\n",
       "      <td>0.979339</td>\n",
       "      <td>-0.039934</td>\n",
       "      <td>293.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>0.010239</td>\n",
       "      <td>0.040956</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>738.00</td>\n",
       "      <td>358.00</td>\n",
       "      <td>0.007483</td>\n",
       "      <td>0.970190</td>\n",
       "      <td>0.091172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fixed_examples_post_v2</th>\n",
       "      <td>591.00</td>\n",
       "      <td>308.00</td>\n",
       "      <td>0.049758</td>\n",
       "      <td>1.042301</td>\n",
       "      <td>-0.028036</td>\n",
       "      <td>206.00</td>\n",
       "      <td>56.00</td>\n",
       "      <td>0.074973</td>\n",
       "      <td>0.543689</td>\n",
       "      <td>0.887895</td>\n",
       "      <td>756.00</td>\n",
       "      <td>339.00</td>\n",
       "      <td>0.005502</td>\n",
       "      <td>0.896825</td>\n",
       "      <td>-0.157903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_examples_post_v2</th>\n",
       "      <td>685.00</td>\n",
       "      <td>356.00</td>\n",
       "      <td>0.083900</td>\n",
       "      <td>1.039416</td>\n",
       "      <td>-0.045502</td>\n",
       "      <td>502.00</td>\n",
       "      <td>139.00</td>\n",
       "      <td>0.112262</td>\n",
       "      <td>0.553785</td>\n",
       "      <td>0.701561</td>\n",
       "      <td>1144.00</td>\n",
       "      <td>755.00</td>\n",
       "      <td>0.001434</td>\n",
       "      <td>1.319930</td>\n",
       "      <td>-0.001486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imitation_random_examples_ht_v2_temperature_0.7</th>\n",
       "      <td>899.00</td>\n",
       "      <td>505.00</td>\n",
       "      <td>0.121153</td>\n",
       "      <td>1.123471</td>\n",
       "      <td>-0.066379</td>\n",
       "      <td>598.00</td>\n",
       "      <td>167.00</td>\n",
       "      <td>0.122074</td>\n",
       "      <td>0.558528</td>\n",
       "      <td>0.991808</td>\n",
       "      <td>1395.00</td>\n",
       "      <td>865.00</td>\n",
       "      <td>0.007478</td>\n",
       "      <td>1.240143</td>\n",
       "      <td>-0.046293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Real</th>\n",
       "      <td>1350.22</td>\n",
       "      <td>5540.52</td>\n",
       "      <td>0.735354</td>\n",
       "      <td>8.176736</td>\n",
       "      <td>-0.080289</td>\n",
       "      <td>996.62</td>\n",
       "      <td>1682.58</td>\n",
       "      <td>0.431627</td>\n",
       "      <td>3.354371</td>\n",
       "      <td>0.399323</td>\n",
       "      <td>2241.48</td>\n",
       "      <td>3171.58</td>\n",
       "      <td>0.090471</td>\n",
       "      <td>2.825327</td>\n",
       "      <td>-0.087781</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 NW_hashtag_number_of_nodes  NW_hashtag_number_of_edges  NW_hashtag_avg_clustering_coefficient  NW_hashtag_avg_degree  NW_hashtag_assortativity  NW_usertag_number_of_nodes  NW_usertag_number_of_edges  NW_usertag_avg_clustering_coefficient  NW_usertag_avg_degree  NW_usertag_assortativity  NW_hashtag_usertag_number_of_nodes  NW_hashtag_usertag_number_of_edges  NW_hashtag_usertag_avg_clustering_coefficient  NW_hashtag_usertag_avg_degree  NW_hashtag_usertag_assortativity\n",
       "base_prompt_v2_temperature_0.7                                       484.00                      237.00                               0.017235               0.979339                 -0.039934                      293.00                        6.00                               0.010239               0.040956                  1.000000                              738.00                              358.00                                       0.007483                       0.970190                          0.091172\n",
       "fixed_examples_post_v2                                               591.00                      308.00                               0.049758               1.042301                 -0.028036                      206.00                       56.00                               0.074973               0.543689                  0.887895                              756.00                              339.00                                       0.005502                       0.896825                         -0.157903\n",
       "random_examples_post_v2                                              685.00                      356.00                               0.083900               1.039416                 -0.045502                      502.00                      139.00                               0.112262               0.553785                  0.701561                             1144.00                              755.00                                       0.001434                       1.319930                         -0.001486\n",
       "imitation_random_examples_ht_v2_temperature_0.7                      899.00                      505.00                               0.121153               1.123471                 -0.066379                      598.00                      167.00                               0.122074               0.558528                  0.991808                             1395.00                              865.00                                       0.007478                       1.240143                         -0.046293\n",
       "Real                                                                1350.22                     5540.52                               0.735354               8.176736                 -0.080289                      996.62                     1682.58                               0.431627               3.354371                  0.399323                             2241.48                             3171.58                                       0.090471                       2.825327                         -0.087781"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\\begin{table}\n",
    "\\centering\n",
    "\\caption{Network metrics for the three classes of networks analysed: hashtag co-occurrence (HT), usertag co-occurrence (UT), and hashtag-user bipartite network (HU). Columns correspond to the four synthetic datasets we analyse and the real dataset. The values reported are averaged over 100 network instances.}\n",
    "\\label{tab:network_metrics}\n",
    "\\begin{tabular}{lccccc}\n",
    "\\toprule\n",
    " & \\bfseries Base Prompt & \\bfseries Fixed Examples & \\bfseries Random Examples & \\bfseries Imitation & \\bfseries Real \\\\\n",
    "\\midrule\n",
    "\\bfseries HT \\# Nodes & 484.00 & 591.00 & 685.00 & 899.00 & 1350.22 \\\\\n",
    "\\bfseries HT \\# Edges & 237.00 & 308.00 & 356.00 & 505.00 & 5540.52 \\\\\n",
    "\\bfseries HT Avg. Clustering Coeff. & 0.02 & 0.05 & 0.08 & 0.12 & 0.74 \\\\\n",
    "\\bfseries HT Avg. Degree & 0.98 & 1.04 & 1.04 & 1.12 & 8.18 \\\\\n",
    "\\bfseries HT Assortativity & -0.04 & -0.03 & -0.05 & -0.07 & -0.08 \\\\\n",
    "\\bfseries UT \\# Nodes & 293.00 & 206.00 & 502.00 & 598.00 & 996.62 \\\\\n",
    "\\bfseries UT \\# Edges & 6.00 & 56.00 & 139.00 & 167.00 & 1682.58 \\\\\n",
    "\\bfseries UT Avg. Clustering Coeff. & 0.01 & 0.07 & 0.11 & 0.12 & 0.43 \\\\\n",
    "\\bfseries UT Avg. Degree & 0.04 & 0.54 & 0.55 & 0.56 & 3.35 \\\\\n",
    "\\bfseries UT Assortativity & 1.00 & 0.89 & 0.70 & 0.99 & 0.40 \\\\\n",
    "\\bfseries HU \\# Nodes & 738.00 & 756.00 & 1144.00 & 1395.00 & 2241.48 \\\\\n",
    "\\bfseries HU \\# Edges & 358.00 & 339.00 & 755.00 & 865.00 & 3171.58 \\\\\n",
    "\\bfseries HU Avg. Clustering Coeff. & 0.01 & 0.01 & 0.00 & 0.01 & 0.09 \\\\\n",
    "\\bfseries HU Avg. Degree & 0.97 & 0.90 & 1.32 & 1.24 & 2.83 \\\\\n",
    "\\bfseries HU Assortativity & 0.09 & -0.16 & -0.00 & -0.05 & -0.09 \\\\\n",
    "\\bottomrule\n",
    "\\end{tabular}\n",
    "\\end{table}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4 - Downstream Task Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "disclosed_data = pd.read_pickle(\"../data/kim_sample_mini.pkl\")\n",
    "disclosed_data[\"sponsorship\"] = disclosed_data[\"sponsorship\"].apply(\n",
    "    lambda x: \"sponsored\" if x == 1 else \"nonsponsored\"\n",
    ")\n",
    "undisclosed_data = pd.read_pickle(\"../data/ann_sample_ad_detection.pkl\")\n",
    "undisclosed_data[\"sponsorship\"] = \"sponsored\"\n",
    "real_data = (\n",
    "    pd.read_pickle(\"../data/df_sample.pkl\")\n",
    "    .sample(1000, random_state=42)\n",
    "    .dropna()\n",
    "    .query(\"caption ! = ''\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 7 --- Performance of the logistic regression model trained on different datasets. Acc. represents the accuracy in detecting undisclosed ads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "downstream_task_columns = [c for c in agg_df.columns if \"ad_detection\" in c]\n",
    "downstream_task_columns.remove(\"ad_detection_accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_map = {\n",
    "    \"ad_detection_precision\": \"P\",\n",
    "    \"ad_detection_recall\": \"R\",\n",
    "    \"ad_detection_f1\": \"F1\",\n",
    "    \"ad_detection_undisclosed_accuracy\": \"Undisc. Acc.\",\n",
    "}\n",
    "\n",
    "downstream_task_table = agg_df.loc[selected_experiments][downstream_task_columns]\n",
    "\n",
    "utils.generate_latex_table(\n",
    "    downstream_task_table,\n",
    "    table_caption=\"Performance of the logistic regression model trained on different datasets. Acc. represents the accuracy in detecting undisclosed ads.\",\n",
    "    table_label=\"tab:downstream_task\",\n",
    "    columns_rename_map=columns_map,\n",
    "    index_rename_map=index_map,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\\begin{table}\n",
    "\\centering\n",
    "\\caption{Performance of the logistic regression model trained on different datasets. Acc. represents the accuracy in detecting undisclosed ads.}\n",
    "\\label{tab:downstream_task}\n",
    "\\begin{tabular}{lcccc}\n",
    "\\toprule\n",
    " & \\bfseries P & \\bfseries R & \\bfseries F1 & \\bfseries Undisc. Acc. \\\\\n",
    "\\midrule\n",
    "\\bfseries Base Prompt & 0.53 & 0.79 & 0.64 & 0.74 \\\\\n",
    "\\bfseries Fixed Examples & 0.65 & 0.68 & 0.66 & 0.40 \\\\\n",
    "\\bfseries Random Examples & 0.63 & 0.82 & 0.71 & 0.51 \\\\\n",
    "\\bfseries Imitation & 0.72 & 0.69 & 0.71 & 0.23 \\\\\n",
    "\\bfseries Real & 0.66 & 0.88 & 0.76 & 0.49 \\\\\n",
    "\\bottomrule\n",
    "\\end{tabular}\n",
    "\\end{table}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup for Table 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "from collections import defaultdict, Counter\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "\n",
    "def get_tfidf_vocabulary(df: pd.DataFrame) -> \"np.array\":\n",
    "    tfidf = TfidfVectorizer()\n",
    "    tfidf.fit_transform(df[\"caption\"].str.lower())\n",
    "    vocab = tfidf.get_feature_names_out()\n",
    "    return vocab\n",
    "\n",
    "\n",
    "def get_vocab_per_class(df: pd.DataFrame) -> \"np.array\":\n",
    "    return get_tfidf_vocabulary(\n",
    "        df.query(\"sponsorship == 'sponsored'\")\n",
    "    ), get_tfidf_vocabulary(df.query(\"sponsorship == 'nonsponsored'\"))\n",
    "\n",
    "\n",
    "def create_vocabs_dict(\n",
    "    df: pd.DataFrame, key_id: str = \"\", per_class: bool = True\n",
    ") -> Dict[str, \"np.array\"]:\n",
    "    vocab_dict = {}\n",
    "    vocab_dict[f\"{key_id}all\"] = get_tfidf_vocabulary(df)\n",
    "    if per_class:\n",
    "        ad_vocab, non_ad_vocab = get_vocab_per_class(df)\n",
    "        vocab_dict[f\"{key_id}ad\"] = ad_vocab\n",
    "        vocab_dict[f\"{key_id}non_ad\"] = non_ad_vocab\n",
    "    return vocab_dict\n",
    "\n",
    "\n",
    "def compare_vocab_overlap(\n",
    "    synthetic_data: pd.DataFrame,\n",
    "    disclosed_data: pd.DataFrame,\n",
    "    undisclosed_data: pd.DataFrame,\n",
    ") -> Dict[str, float]:\n",
    "    synthetic_vocab_dict = create_vocabs_dict(synthetic_data)\n",
    "    disclosed_vocab_dict = create_vocabs_dict(disclosed_data, \"disclosed_\")\n",
    "    undisclosed_vocab_dict = create_vocabs_dict(\n",
    "        undisclosed_data, \"undisclosed_\", per_class=False\n",
    "    )\n",
    "    overlap_dict = defaultdict(dict)\n",
    "    for k, v in {**disclosed_vocab_dict, **undisclosed_vocab_dict}.items():\n",
    "        overlap_dict[k] = len(set(synthetic_vocab_dict[\"all\"]) & set(v)) / len(\n",
    "            set(synthetic_vocab_dict[\"all\"])\n",
    "        )\n",
    "    return overlap_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_overlap = {}\n",
    "\n",
    "for exp in selected_experiments:\n",
    "    data = (\n",
    "        pd.read_pickle(f\"../results/{exp}/final_df.pkl\").dropna().query(\"caption != ''\")\n",
    "        if exp != \"Real\"\n",
    "        else real_data.copy()\n",
    "    )\n",
    "    vocab_overlap[exp] = compare_vocab_overlap(\n",
    "        data, disclosed_data=disclosed_data, undisclosed_data=undisclosed_data\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "bootstrap_vocab_overlap = defaultdict(float)\n",
    "\n",
    "for i in range(100):\n",
    "    for k, v in compare_vocab_overlap(\n",
    "        sample_real(full_data, i), disclosed_data, undisclosed_data\n",
    "    ).items():\n",
    "        bootstrap_vocab_overlap[k] += v\n",
    "\n",
    "bootstrap_vocab_overlap = {k: v / 100 for k, v in bootstrap_vocab_overlap.items()}\n",
    "\n",
    "vocab_overlap[\"Real\"] = bootstrap_vocab_overlap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 8 -- Overlap between unigrams from each dataset and the test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_detection_overlap_columns = [\"disclosed_ad\", \"undisclosed_all\"]\n",
    "column_map = {\"disclosed_ad\": \"Disclosed\", \"undisclosed_all\": \"Undisclosed\"}\n",
    "\n",
    "ad_detection_overlap_table = pd.DataFrame(vocab_overlap).T[ad_detection_overlap_columns]\n",
    "for c in ad_detection_overlap_table.columns:\n",
    "    ad_detection_overlap_table[c] = ad_detection_overlap_table[c] * 100\n",
    "\n",
    "utils.generate_latex_table(\n",
    "    ad_detection_overlap_table,\n",
    "    table_caption=\"Overlap between unigrams from each dataset and the test sets.\",\n",
    "    table_label=\"tab:ad_detection_overlap\",\n",
    "    columns_rename_map=column_map,\n",
    "    index_rename_map=index_map,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\\begin{table}\n",
    "\\centering\n",
    "\\caption{Overlap between unigrams from each dataset and the test sets.}\n",
    "\\label{tab:ad_detection_overlap}\n",
    "\\begin{tabular}{lcc}\n",
    "\\toprule\n",
    " & \\bfseries Disclosed & \\bfseries Undisclosed \\\\\n",
    "\\midrule\n",
    "\\bfseries Base Prompt & 56.67 & 48.46 \\\\\n",
    "\\bfseries Fixed Examples & 55.02 & 48.07 \\\\\n",
    "\\bfseries Random Examples & 52.77 & 45.98 \\\\\n",
    "\\bfseries Imitation & 50.25 & 44.61 \\\\\n",
    "\\bfseries Real & 44.24 & 40.22 \\\\\n",
    "\\bottomrule\n",
    "\\end{tabular}\n",
    "\\end{table}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['base_prompt_v2_temperature_0.7',\n",
       " 'fixed_examples_post_v2',\n",
       " 'random_examples_post_v2',\n",
       " 'imitation_random_examples_ht_v2_temperature_0.7']"
      ]
     },
     "execution_count": 605,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_selected_experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup for Table 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from instasynth import evaluation\n",
    "\n",
    "disclosed_data = pd.read_pickle(\"../data/kim_sample_mini.pkl\")\n",
    "undisclosed_data = pd.read_pickle(\"../data/ann_sample_ad_detection.pkl\")\n",
    "\n",
    "\n",
    "def _evaluate_with_augmented_data(df: pd.DataFrame, real_data: pd.DataFrame):\n",
    "    aug_data = pd.concat([df, real_data])\n",
    "    clf_eval = evaluation.ClassificationAnalyser(\n",
    "        aug_data.copy(),\n",
    "        evaluation_data=disclosed_data,\n",
    "        evaluation_data_ann=undisclosed_data,\n",
    "    )\n",
    "    return clf_eval.ad_detection_performance()\n",
    "\n",
    "\n",
    "def evaluate_with_augmented_data(df: pd.DataFrame, full_df: pd.DataFrame):\n",
    "    performance_dict = defaultdict(float)\n",
    "    for i in range(100):\n",
    "        real_data = sample_real(full_df, i)\n",
    "        for k, v in _evaluate_with_augmented_data(df, real_data).items():\n",
    "            performance_dict[k] += v\n",
    "    return {k: v / 100 for k, v in performance_dict.items()}\n",
    "\n",
    "\n",
    "augmented_performance = {\n",
    "    exp: evaluate_with_augmented_data(\n",
    "        pd.read_pickle(f\"../results/{exp}/final_df.pkl\"), full_data\n",
    "    )\n",
    "    for exp in selected_experiments\n",
    "    if exp != \"Real\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_real_2k(full_df: pd.DataFrame, seed: int):\n",
    "    spons = full_df.query(\"sponsorship == 'sponsored'\").sample(1000, random_state=seed)\n",
    "    nonspons = full_df.query(\"sponsorship == 'nonsponsored'\").sample(\n",
    "        1000, random_state=seed\n",
    "    )\n",
    "    return pd.concat([spons, nonspons]).sample(frac=1)\n",
    "\n",
    "\n",
    "bootstrap_real_2k_performance = defaultdict(float)\n",
    "\n",
    "for i in range(100):\n",
    "    sample = sample_real_2k(full_data, i)\n",
    "    clf_eval = evaluation.ClassificationAnalyser(\n",
    "        sample.copy(),\n",
    "        evaluation_data=disclosed_data,\n",
    "        evaluation_data_ann=undisclosed_data,\n",
    "    )\n",
    "    for k, v in clf_eval.ad_detection_performance().items():\n",
    "        bootstrap_real_2k_performance[k] += v\n",
    "bootstrap_real_2k_performance = {\n",
    "    k: v / 100 for k, v in bootstrap_real_2k_performance.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_performance[\"Real\"] = bootstrap_real_2k_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 9 -- Performance of the logistic regression model trained on augmented datasets. Each synthetic dataset is augmented with a sample of 1k captions from the real data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_map = {\n",
    "    \"ad_detection_precision\": \"P\",\n",
    "    \"ad_detection_recall\": \"R\",\n",
    "    \"ad_detection_f1\": \"F1\",\n",
    "    \"ad_detection_undisclosed_accuracy\": \"Undisc. Acc.\",\n",
    "}\n",
    "\n",
    "augment_performance_table = pd.DataFrame(augmented_performance).T.loc[\n",
    "    selected_experiments\n",
    "][downstream_task_columns]\n",
    "\n",
    "utils.generate_latex_table(\n",
    "    augment_performance_table,\n",
    "    table_caption=\"Performance of the logistic regression model trained on augmented datasets. Each synthetic dataset is augmented with a sample of 1k captions from the real data.\",\n",
    "    table_label=\"tab:ad_detection_aug\",\n",
    "    columns_rename_map=columns_map,\n",
    "    index_rename_map=index_map,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\\begin{table}\n",
    "\\centering\n",
    "\\caption{Performance of the logistic regression model trained on augmented datasets. Each synthetic dataset is augmented with a sample of 1k captions from the real data.}\n",
    "\\label{tab:ad_detection_aug}\n",
    "\\begin{tabular}{lcccc}\n",
    "\\toprule\n",
    " & \\bfseries P & \\bfseries R & \\bfseries F1 & \\bfseries Undisc. Acc. \\\\\n",
    "\\midrule\n",
    "\\bfseries Base Prompt & 0.63 & 0.90 & 0.74 & 0.57 \\\\\n",
    "\\bfseries Fixed Examples & 0.68 & 0.89 & 0.77 & 0.47 \\\\\n",
    "\\bfseries Random Examples & 0.66 & 0.89 & 0.76 & 0.48 \\\\\n",
    "\\bfseries Imitation & 0.70 & 0.88 & 0.78 & 0.38 \\\\\n",
    "\\bfseries Real & 0.69 & 0.89 & 0.78 & 0.42 \\\\\n",
    "\\bottomrule\n",
    "\\end{tabular}\n",
    "\\end{table}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
